<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="J. Schütt" />


<title>Classifying Weight Lifting Exercises through Human Activity Data</title>

<script src="pml-course-project_files/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="pml-course-project_files/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="pml-course-project_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="pml-course-project_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="pml-course-project_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="pml-course-project_files/navigation-1.1/tabsets.js"></script>
<link href="pml-course-project_files/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="pml-course-project_files/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Classifying Weight Lifting Exercises through Human Activity Data</h1>
<h4 class="author">J. Schütt</h4>

</div>


<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>This report deals with a dataset concerning dumbbell curls that was collected using sensors on the arm, forearm, belt and the dumbell. Our aim is to classify the exercise data into five classes of wrongly performed exercises. See <a href="http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har">here</a> for more details and the original data.</p>
</div>
<div id="data-preparation-code-book" class="section level2">
<h2>Data Preparation (Code Book)</h2>
<p>First, we download the data and split it into a training and testing set (75% training, 25% testing). Additionally, we load a final testing set of 20 observations that is unlabeled.</p>
<pre class="r"><code>library(ggplot2)
library(caret)

# download data
if(!file.exists(&quot;pml-training.csv&quot;))
    download.file(&quot;https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv&quot;, destfile = &quot;pml-training.csv&quot;, method=&quot;curl&quot;)
if(!file.exists(&quot;pml-testing.csv&quot;))
    download.file(&quot;https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv&quot;, destfile = &quot;pml-testing.csv&quot;, method=&quot;curl&quot;)

set.seed(4538)

# load training data
data &lt;- read.csv(&quot;pml-training.csv&quot;)
# split the data into training and testing sets
inTrain &lt;- createDataPartition(y=data$classe, p=0.75, list=FALSE)
training &lt;- data[inTrain,]
testing &lt;- data[-inTrain,]

final_test &lt;- read.csv(&quot;pml-testing.csv&quot;)</code></pre>
<div id="cleaning-the-data" class="section level3">
<h3>Cleaning the Data</h3>
<p>Of the original 160 features many are very sparse (e.g. contain almost exclusively NA entries or factor variables with mostly blank entries). We completely remove these columns. The original data consists of timeseries and the original <a href="http://web.archive.org/web/20161224072740/http://groupware.les.inf.puc-rio.br/work.jsf?p1=11201">research paper</a> made use of that fact. However, since the final testing set we are interested in does not contain timeseries data, we also remove columns concerning time. Finally, we remove the subjects names, since our analysis is meant to be independent of the subject. We also remove the first column, which just consists of the indices. After this, We are left with 52 numeric (or integer) columns and one column for the classes.</p>
<pre class="r"><code># remove columns with NA entries
training2 &lt;- training[sapply(training, function(x) !any(is.na(x)))] 
# remove factor variables
training2 &lt;- training2[sapply(training2, function(x) class(x) %in% c(&quot;integer&quot;,&quot;numeric&quot;))]
# remove index, user and time related features
training2 &lt;- training2[,-c(1,2,3,4)]
# add the classes again
training2$classe &lt;- training$classe

# save the used columns and restrict the testing data
used_cols &lt;- names(training2)
testing &lt;- testing[,used_cols]
final_test &lt;- final_test[,used_cols[1:52]] # does not have a &quot;classe&quot; column</code></pre>
</div>
</div>
<div id="feature-selection" class="section level2">
<h2>Feature Selection</h2>
<p>Probably because we ignored the timeseries data, our features display highly nonlinear behaviour that does not easily lend itself to separate the classes. As an example, consider the following plot.</p>
<pre class="r"><code>ggplot(training2, aes(x=accel_forearm_x, y=accel_forearm_y, col=classe)) + geom_point(alpha = .5)</code></pre>
<p><img src="pml-course-project_files/figure-html/unnamed-chunk-3-1.png" width="672" /> Moreover, many of the features have similar distributions. For example:</p>
<pre class="r"><code>qplot(x=accel_dumbbell_y, color = classe, geom = &quot;density&quot;, data=training2) </code></pre>
<p><img src="pml-course-project_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>Therefore, we perform a principal component analysis instead of selecting suitable features by hand. We aim to explain 95% of the variability with the chosen principal components. It turns out that this halves the number of features, which helps to speed up the training considerably. We use the PCA obtained from our training set to transform the testing and final testing set as well.</p>
<pre class="r"><code># do pca excluding classe
preProc &lt;- preProcess(training2[1:52], method = &quot;pca&quot;, thresh = 0.95)
training_pca &lt;- predict(preProc,training2[1:52])
#apply pca to test sets
testing_pca &lt;- predict(preProc, testing[1:52])
final_test_pca &lt;- predict(preProc, final_test)</code></pre>
<p>Interestingly, even the first two principal components do not show obvious linear or separating behaviour.</p>
<pre class="r"><code>qplot(x=training_pca[,1], y=training_pca[,2], color=training2$classe, alpha=.5, xlab=&quot;principal component 1&quot;, ylab=&quot;principal component 2&quot;) + theme(legend.position=&quot;none&quot;)</code></pre>
<p><img src="pml-course-project_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
</div>
<div id="model-selection-and-training" class="section level2">
<h2>Model Selection and Training</h2>
<p>Since we have considerable nonlinearity, we choose a random forest as our model. The training takes quite a bit of time and this is one of the reasons, we only use half of the principal components (epxplaining 95% of the variabilty).</p>
<pre class="r"><code>modPCAFit &lt;- train(y=training2$classe, x=training_pca, method = &quot;rf&quot;)</code></pre>
</div>
<div id="model-testing-and-predictions" class="section level2">
<h2>Model Testing and Predictions</h2>
<p>Next, we test our model on the testing set.</p>
<pre class="r"><code>pred &lt;- predict(modPCAFit, testing_pca)
conf &lt;- confusionMatrix(pred,testing$classe)
conf$byClass</code></pre>
<pre><code>##          Sensitivity Specificity Pos Pred Value Neg Pred Value Precision
## Class: A   0.9949821   0.9943004      0.9857955      0.9979977 0.9857955
## Class: B   0.9715490   0.9957016      0.9818956      0.9931904 0.9818956
## Class: C   0.9684211   0.9893801      0.9506315      0.9933052 0.9506315
## Class: D   0.9614428   0.9948780      0.9735516      0.9924574 0.9735516
## Class: E   0.9844617   0.9987509      0.9943946      0.9965105 0.9943946
##             Recall        F1 Prevalence Detection Rate
## Class: A 0.9949821 0.9903675  0.2844617      0.2830343
## Class: B 0.9715490 0.9766949  0.1935155      0.1880098
## Class: C 0.9684211 0.9594438  0.1743475      0.1688418
## Class: D 0.9614428 0.9674593  0.1639478      0.1576264
## Class: E 0.9844617 0.9894032  0.1837276      0.1808728
##          Detection Prevalence Balanced Accuracy
## Class: A            0.2871126         0.9946412
## Class: B            0.1914763         0.9836253
## Class: C            0.1776101         0.9789006
## Class: D            0.1619086         0.9781604
## Class: E            0.1818923         0.9916063</code></pre>
<p>As can be seen, we have very high values of sensitivity, specificity and accuracy for every class. Overall, we have an accuracy of 0.978385. In other words, we can expect the out of sample error rate to be around 0.021615.</p>
<pre class="r"><code>df &lt;- data.frame(conf$table)
ggplot(data=df, aes(Prediction, Reference)) + geom_tile(aes(fill = Freq), colour = &quot;white&quot;) + scale_fill_gradient(low = &quot;red2&quot;, high = &quot;yellow&quot;) +
  geom_text(aes(label=Freq)) + labs(fill = &quot;&quot;)</code></pre>
<p><img src="pml-course-project_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>Finally, we obtain the following predictions for the final testing set.</p>
<pre class="r"><code>pred_final &lt;- predict(modPCAFit, final_test_pca)
pred_final</code></pre>
<pre><code>##  [1] B A A A A E D B A A A C B A E E A B B B
## Levels: A B C D E</code></pre>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
